{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA2EbGhP_ARz",
        "outputId": "42748876-c44b-4e94-af28-fa08c6900057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQu2bphS-haw",
        "outputId": "5bc46bc5-9792-4b64-f8bd-10b190c399c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI Models:\n",
            "- tts-1-hd-1106\n",
            "- tts-1-hd\n",
            "- dall-e-2\n",
            "- text-embedding-3-large\n",
            "- gpt-3.5-turbo-0125\n",
            "- gpt-4o-mini\n",
            "- gpt-4o-mini-2024-07-18\n",
            "- gpt-3.5-turbo\n",
            "- tts-1-1106\n",
            "- whisper-1\n",
            "- tts-1\n",
            "- gpt-3.5-turbo-16k\n",
            "- text-embedding-3-small\n",
            "- gpt-3.5-turbo-1106\n",
            "- gpt-3.5-turbo-instruct-0914\n",
            "- gpt-3.5-turbo-instruct\n",
            "- babbage-002\n",
            "- davinci-002\n",
            "- dall-e-3\n",
            "- text-embedding-ada-002\n",
            "\n",
            "Hugging Face Models:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- bert-base-uncased\n",
            "- gpt2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- roberta-base\n",
            "\n",
            "Gemini Models:\n",
            "- Gemini-1\n",
            "- Gemini-2\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# To list OpenAI models\n",
        "def list_openai_models():\n",
        "    openai.api_key = 'API_SECRET'\n",
        "    models = openai.Model.list()\n",
        "    print(\"OpenAI Models:\")\n",
        "    for model in models['data']:\n",
        "        print(f\"- {model['id']}\")\n",
        "\n",
        "# To list hugging face models\n",
        "def list_huggingface_models():\n",
        "    huggingface_models = [\"bert-base-uncased\", \"gpt2\", \"roberta-base\"]\n",
        "    print(\"\\nHugging Face Models:\")\n",
        "    for model_name in huggingface_models:\n",
        "        model = AutoModel.from_pretrained(model_name)\n",
        "        print(f\"- {model_name}\")\n",
        "\n",
        "\n",
        "# To list Gemnini models\n",
        "def list_gemini_models():\n",
        "    # Placeholder for Gemini models\n",
        "    gemini_models = [\"Gemini-1\", \"Gemini-2\"]\n",
        "    print(\"\\nGemini Models:\")\n",
        "    for model in gemini_models:\n",
        "        print(f\"- {model}\")\n",
        "\n",
        "# Call the functions to print the models\n",
        "list_openai_models()\n",
        "list_huggingface_models()\n",
        "list_gemini_models()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
